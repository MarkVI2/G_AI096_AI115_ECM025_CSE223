{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "82cbc8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import logging\n",
    "import argparse\n",
    "import multiprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Add the Code directory to Python path\n",
    "notebook_path = os.getcwd()\n",
    "code_dir = os.path.dirname(notebook_path)\n",
    "if code_dir not in sys.path:\n",
    "    sys.path.append(code_dir)\n",
    "\n",
    "from pipelines.clustering_pipeline import run_clustering\n",
    "from pipelines.classification_pipeline import run_classification\n",
    "from pipelines.regression_pipeline import run_regression\n",
    "from pipelines.risk_pipeline import run_risk_assessment\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s %(message)s\",\n",
    "    handlers=[logging.StreamHandler()]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54dd7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_visualization_type():\n",
    "    print(\"Select visualization type:\")\n",
    "    print(\"1. 2D Visualizations\")\n",
    "    print(\"2. 3D Visualizations\")\n",
    "    print(\"3. Both\")\n",
    "    return int(input(\"Enter your choice (1-3): \"))\n",
    "\n",
    "def plot_clustering_results(cluster_results):\n",
    "    vis_type = select_visualization_type()\n",
    "    \n",
    "    if vis_type in [1, 3]:\n",
    "        # 2D plots\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        sns.scatterplot(data=cluster_results['data'], x='cycle', y='sensor1', hue='cluster')\n",
    "        plt.title('Sensor 1 Degradation Pattern')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        sns.boxplot(data=cluster_results['data'], x='cluster', y='rul')\n",
    "        plt.title('RUL Distribution by Cluster')\n",
    "\n",
    "    if vis_type in [2, 3]:\n",
    "        # 3D plot\n",
    "        fig = go.Figure(data=[go.Scatter3d(\n",
    "            x=cluster_results['data']['sensor1'],\n",
    "            y=cluster_results['data']['sensor2'],\n",
    "            z=cluster_results['data']['sensor3'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=cluster_results['data']['cluster'],\n",
    "                colorscale='Viridis',\n",
    "            )\n",
    "        )])\n",
    "        fig.update_layout(title='3D Cluster Distribution')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6ec7fb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "notebook_path = os.getcwd()\n",
    "code_dir = os.path.dirname(notebook_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "435ff98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data path: c:\\Users\\shriv.SHRI\\Documents\\GitHub\\G_AI096_AI115_ECM025_CSE223\\Code\\data\n"
     ]
    }
   ],
   "source": [
    "class Args:\n",
    "    phase = 0  # 0=all, 1=clustering, 2=classification, 3=regression, 4=risk\n",
    "    data_path = os.path.join(os.path.dirname(os.getcwd()), 'Code', 'data')  # Use absolute path\n",
    "    datasets = \"FD001,FD003\"\n",
    "    n_jobs = None  # Will be auto-calculated\n",
    "\n",
    "args = Args()\n",
    "print(f\"Data path: {args.data_path}\")  # Print to verify the path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a940b6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available files in data directory:\n",
      "['c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\train\\\\train_FD001.txt', 'c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\train\\\\train_FD002.txt', 'c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\train\\\\train_FD003.txt', 'c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\train\\\\train_FD004.txt']\n",
      "['c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\test\\\\test_FD001.txt', 'c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\test\\\\test_FD002.txt', 'c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\test\\\\test_FD003.txt', 'c:\\\\Users\\\\shriv.SHRI\\\\Documents\\\\GitHub\\\\G_AI096_AI115_ECM025_CSE223\\\\Code\\\\data\\\\test\\\\test_FD004.txt']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(\"Available files in data directory:\")\n",
    "print(glob.glob(os.path.join(args.data_path, 'train', '*.txt')))\n",
    "print(glob.glob(os.path.join(args.data_path, 'test', '*.txt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "843aa11d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 7 parallel jobs for processing\n",
      "Processing datasets: ['FD001', 'FD003']\n"
     ]
    }
   ],
   "source": [
    "# Determine number of parallel jobs\n",
    "if args.n_jobs is None:\n",
    "    n_jobs = max(1, multiprocessing.cpu_count() - 1)\n",
    "else:\n",
    "    n_jobs = args.n_jobs\n",
    "\n",
    "# Parse datasets\n",
    "dataset_ids = args.datasets.split(',') if args.datasets else [\"FD001\", \"FD003\"]\n",
    "\n",
    "print(f\"Using {n_jobs} parallel jobs for processing\")\n",
    "print(f\"Processing datasets: {dataset_ids}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4426465b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Phase 1: Clustering for degradation stages...\n",
      "Loading dataset FD001...\n",
      "Loaded 20631 training samples and 13096 test samples\n",
      "Preprocessing data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m args\u001b[38;5;241m.\u001b[39mphase \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRunning Phase 1: Clustering for degradation stages...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     cluster_results \u001b[38;5;241m=\u001b[39m \u001b[43mrun_clustering\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Remove n_jobs parameter\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cluster_results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m         plot_clustering_results(cluster_results)\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\Documents\\GitHub\\G_AI096_AI115_ECM025_CSE223\\Code\\pipelines\\clustering_pipeline.py:669\u001b[0m, in \u001b[0;36mrun_clustering\u001b[1;34m(data_dir)\u001b[0m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    658\u001b[0m \u001b[38;5;124;03mConvenience wrapper to run the clustering pipeline.\u001b[39;00m\n\u001b[0;32m    659\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    660\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m ClusteringPipeline(\n\u001b[0;32m    661\u001b[0m     data_dir\u001b[38;5;241m=\u001b[39mdata_dir,\n\u001b[0;32m    662\u001b[0m     n_clusters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    667\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    668\u001b[0m )\n\u001b[1;32m--> 669\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mrun_clustering()\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pipeline\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\Documents\\GitHub\\G_AI096_AI115_ECM025_CSE223\\Code\\pipelines\\clustering_pipeline.py:133\u001b[0m, in \u001b[0;36mClusteringPipeline.preprocess_data\u001b[1;34m(self, add_engineered_features)\u001b[0m\n\u001b[0;32m    131\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_with_rul\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Fit and transform training data\u001b[39;00m\n\u001b[1;32m--> 133\u001b[0m transformed_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_remaining_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_engineered_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_sensor_diff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_engineered_features\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Sub-sample ~60% from each engine (unit_number) for reproducible training split\u001b[39;00m\n\u001b[0;32m    139\u001b[0m sampled_train \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    140\u001b[0m     transformed_train\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit_number\u001b[39m\u001b[38;5;124m'\u001b[39m, group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m d: d\u001b[38;5;241m.\u001b[39msample(frac\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.6\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_state))\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    144\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\Documents\\GitHub\\G_AI096_AI115_ECM025_CSE223\\Code\\data\\preprocessor.py:118\u001b[0m, in \u001b[0;36mCMAPSSPreprocessor.fit_transform\u001b[1;34m(self, train_df, sensor_columns, operating_setting_columns, add_remaining_features, add_sensor_diff, window_size)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03mFit the preprocessor and transform the data in one step.\u001b[39;00m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;124;03m\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m    Transformed DataFrame\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(train_df, sensor_columns, operating_setting_columns)\n\u001b[1;32m--> 118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_remaining_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_sensor_diff\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\Documents\\GitHub\\G_AI096_AI115_ECM025_CSE223\\Code\\data\\preprocessor.py:91\u001b[0m, in \u001b[0;36mCMAPSSPreprocessor.transform\u001b[1;34m(self, df, add_remaining_features, add_sensor_diff, window_size)\u001b[0m\n\u001b[0;32m     88\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_add_remaining_features(result_df)\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_sensor_diff:\n\u001b[1;32m---> 91\u001b[0m     result_df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_sensor_differences\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;66;03m# Scale features\u001b[39;00m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalization_method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\Documents\\GitHub\\G_AI096_AI115_ECM025_CSE223\\Code\\data\\preprocessor.py:270\u001b[0m, in \u001b[0;36mCMAPSSPreprocessor._add_sensor_differences\u001b[1;34m(self, df, window_size)\u001b[0m\n\u001b[0;32m    268\u001b[0m \u001b[38;5;66;03m# Calculate rolling mean\u001b[39;00m\n\u001b[0;32m    269\u001b[0m roll_mean_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_roll_mean_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 270\u001b[0m unit_data[roll_mean_col] \u001b[38;5;241m=\u001b[39m \u001b[43munit_data\u001b[49m\u001b[43m[\u001b[49m\u001b[43msensor\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwindow_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# Calculate rolling standard deviation\u001b[39;00m\n\u001b[0;32m    273\u001b[0m roll_std_col \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msensor\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_roll_std_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwindow_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:2259\u001b[0m, in \u001b[0;36mRolling.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   2216\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   2217\u001b[0m     template_header,\n\u001b[0;32m   2218\u001b[0m     create_section_header(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameters\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2257\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2258\u001b[0m ):\n\u001b[1;32m-> 2259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2261\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1625\u001b[0m, in \u001b[0;36mRollingAndExpandingMixin.mean\u001b[1;34m(self, numeric_only, engine, engine_kwargs)\u001b[0m\n\u001b[0;32m   1623\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_numba_apply(sliding_mean, engine_kwargs)\n\u001b[0;32m   1624\u001b[0m window_func \u001b[38;5;241m=\u001b[39m window_aggregations\u001b[38;5;241m.\u001b[39mroll_mean\n\u001b[1;32m-> 1625\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwindow_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:619\u001b[0m, in \u001b[0;36mBaseWindow._apply\u001b[1;34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingle\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 619\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_columnwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:472\u001b[0m, in \u001b[0;36mBaseWindow._apply_columnwise\u001b[1;34m(self, homogeneous_func, name, numeric_only)\u001b[0m\n\u001b[0;32m    470\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_numeric_only(name, numeric_only)\n\u001b[0;32m    471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 472\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_data(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_selected_obj, numeric_only)\n\u001b[0;32m    475\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:456\u001b[0m, in \u001b[0;36mBaseWindow._apply_series\u001b[1;34m(self, homogeneous_func, name)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo numeric types to aggregate\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mhomogeneous_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    457\u001b[0m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slice_axis_for_step(obj\u001b[38;5;241m.\u001b[39mindex, result)\n\u001b[0;32m    458\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor(result, index\u001b[38;5;241m=\u001b[39mindex, name\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mname)\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:614\u001b[0m, in \u001b[0;36mBaseWindow._apply.<locals>.homogeneous_func\u001b[1;34m(values)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, start, end, min_periods, \u001b[38;5;241m*\u001b[39mnumba_args)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 614\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcalc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\shriv.SHRI\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:611\u001b[0m, in \u001b[0;36mBaseWindow._apply.<locals>.homogeneous_func.<locals>.calc\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    602\u001b[0m start, end \u001b[38;5;241m=\u001b[39m window_indexer\u001b[38;5;241m.\u001b[39mget_window_bounds(\n\u001b[0;32m    603\u001b[0m     num_values\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(x),\n\u001b[0;32m    604\u001b[0m     min_periods\u001b[38;5;241m=\u001b[39mmin_periods,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    607\u001b[0m     step\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep,\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_window_bounds(start, end, \u001b[38;5;28mlen\u001b[39m(x))\n\u001b[1;32m--> 611\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnumba_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cluster_results = None\n",
    "if args.phase == 0 or args.phase == 1:\n",
    "    print(\"Running Phase 1: Clustering for degradation stages...\")\n",
    "    cluster_results = run_clustering(args.data_path)  # Remove n_jobs parameter\n",
    "    \n",
    "    if cluster_results is not None:\n",
    "        plot_clustering_results(cluster_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2390f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_results = None\n",
    "if args.phase == 0 or args.phase == 2:\n",
    "    print(\"Running Phase 2: Classification for degradation stage prediction...\")\n",
    "    classification_results = run_classification(\n",
    "        args.data_path,\n",
    "        cluster_results if args.phase == 0 else None,\n",
    "        n_jobs=n_jobs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef9cf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classification_results(classification_results):\n",
    "    vis_type = select_visualization_type()\n",
    "    \n",
    "    if vis_type in [1, 3]:\n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(classification_results['confusion_matrix'], \n",
    "                   annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title('Confusion Matrix')\n",
    "        plt.show()\n",
    "        \n",
    "        # Plot feature importance\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(x=classification_results['feature_importance'].index,\n",
    "                   y=classification_results['feature_importance'].values)\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.title('Feature Importance')\n",
    "        plt.show()\n",
    "\n",
    "    if vis_type in [2, 3]:\n",
    "        # 3D Decision Boundary (if available)\n",
    "        if 'decision_boundary' in classification_results:\n",
    "            fig = go.Figure(data=go.Volume(\n",
    "                x=classification_results['decision_boundary']['x'],\n",
    "                y=classification_results['decision_boundary']['y'],\n",
    "                z=classification_results['decision_boundary']['z'],\n",
    "                value=classification_results['decision_boundary']['pred'],\n",
    "                opacity=0.1,\n",
    "                surface_count=20,\n",
    "            ))\n",
    "            fig.update_layout(title='3D Decision Boundary')\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adad5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_results = None\n",
    "if args.phase == 0 or args.phase == 3:\n",
    "    print(\"Running Phase 3: Regression model for time-to-failure prediction...\")\n",
    "    regression_results = run_regression(\n",
    "        datasets=dataset_ids,\n",
    "        classifier='random_forest',\n",
    "        base_path=os.path.dirname(args.data_path),\n",
    "        n_jobs=n_jobs\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6f069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_results(regression_results):\n",
    "    vis_type = select_visualization_type()\n",
    "    \n",
    "    if vis_type in [1, 3]:\n",
    "        # Actual vs Predicted\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.scatterplot(x=regression_results['actual'], \n",
    "                       y=regression_results['predicted'])\n",
    "        plt.plot([0, max(regression_results['actual'])], \n",
    "                 [0, max(regression_results['actual'])], \n",
    "                 'r--')\n",
    "        plt.xlabel('Actual RUL')\n",
    "        plt.ylabel('Predicted RUL')\n",
    "        plt.title('Actual vs Predicted RUL')\n",
    "        plt.show()\n",
    "\n",
    "    if vis_type in [2, 3]:\n",
    "        # 3D Time Series\n",
    "        fig = go.Figure(data=[go.Scatter3d(\n",
    "            x=regression_results['time'],\n",
    "            y=regression_results['sensor_values'],\n",
    "            z=regression_results['predictions'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=regression_results['rul'],\n",
    "                colorscale='Viridis',\n",
    "            )\n",
    "        )])\n",
    "        fig.update_layout(title='3D RUL Prediction Visualization')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a24a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_risk_assessment(risk_results):\n",
    "    vis_type = select_visualization_type()\n",
    "    \n",
    "    if vis_type in [1, 3]:\n",
    "        # Risk Distribution\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.subplot(131)\n",
    "        sns.histplot(data=risk_results['risk_scores'])\n",
    "        plt.title('Risk Score Distribution')\n",
    "        \n",
    "        plt.subplot(132)\n",
    "        sns.barplot(x='category', y='count', \n",
    "                   data=risk_results['risk_categories'])\n",
    "        plt.title('Risk Categories')\n",
    "\n",
    "    if vis_type in [2, 3]:\n",
    "        # 3D Risk Surface\n",
    "        fig = go.Figure(data=[go.Surface(\n",
    "            z=risk_results['risk_surface'],\n",
    "            colorscale='RdYlGn_r'\n",
    "        )])\n",
    "        fig.update_layout(title='3D Risk Surface')\n",
    "        fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1389e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pipeline execution complete!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
